{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TME Robotique et apprentissage: evolution de structures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Étudiant: Nom: ZUO Prénom: Nicolas\n",
    "* Si binome: Nom: WILLAIME-ANGONIN Prénom: Julien\n",
    "\n",
    "Merci à chaque membre du binome de soumettre en son nom sous moodle, cela facilite le suivi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Ce TME est composé de deux parties indépendantes qui s'appuieront toutes deux sur le framework DEAP que vous avez utilisé lors du dernier TME. \n",
    "\n",
    "Dans la première partie, vous ferez de la regression symbolique avec de la programmation génétique.\n",
    "\n",
    "Dans la seconde partie, vous testerez l'expérience de Lehman et Stanley sur novelty search. \n",
    "\n",
    "Des squelettes de code vous sont fournis. Les zones à compléter sont repérées par des '##'.\n",
    "\n",
    "Merci de soumettre le code complété ainsi que le notebook auquel vous aurez ajouté les commentaires et tracés de courbes nécessaires pour répondre aux questions. MERCI DE NE PAS SOUMETTRE VOS FICHIERS DE DONNEES. La soumission se fait directement sur moodle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Regression symbolique\n",
    "\n",
    "Vous allez utiliser la programmation génétique pour retrouver des équations à partir de données. \n",
    "Vous utiliserez pour cela les fonctions proposées par DEAP:\n",
    "https://deap.readthedocs.io/en/master/tutorials/advanced/gp.html\n",
    "\n",
    "\n",
    "### **1.1-** Complétez le code qui vous a été fourni `symbolic_regression.py`. En vous appuyant sur DEAP, vous implémenterez 3 stratégies: \n",
    "* une stratégie purement élitiste visant à minimiser l'erreur d'approximation uniquement, \n",
    "* la stratégie avec double tournoi, le premier tournoi choisissant les individus avec les erreurs les plus faibles et le second tournoi choisissant les individus avec le modèle le plus simple\n",
    "* une stratégie multi-objectif s'appuyant sur NSGA-2 avec l'erreur d'approximation comme premier objectif et la taille du modèle en deuxième objectif (les deux étant à minimiser)\n",
    "\n",
    "Vous testerez votre code sur 2 fonctions simples (par exemple f(x,y)=x*y+cos(x) et f(x,y,z)=x^2+y^2+z^2) avec le jeu de fonctions primitives suivant: +, -, *, / (protected_div), cos et sin. Vous pourrez ajouter une constante (1) et une constante éphémère (variable aléatoire uniforme entre -1 et 1). Vous génèrerez un ensemble de données d'entrainement et un ensemble que vous utiliserez pour vérifier s'il y a eu surapprentissage. Vous pourrez générer, par exemple, 30 valeurs différentes de x et 30 valeurs différentes de y. Vous indiquerez dans votre réponse les opérateurs de mutation et de croisement que vous avez utilisé (remarque: si vous voulez combiner plusieurs opérateurs de mutation ou de croisement, il faut définir un nouvel opérateur qui gère cette combinaison).\n",
    "\n",
    "\n",
    "Vous regarderez les arbres générés et indiquerez le nombre de fois que la fonction a été retrouvée sur une dizaine d'expériences. Vous comparerez la taille des fonctions générées selon la variante de sélection utilisée. \n",
    "\n",
    "Remarque1: pour rappel, la programmation génétique utilise généralement de grandes populations. Il vous est recommandé d'utiliser des tailles de 400 minimum. En une centaine de générations, vous devriez pouvoir observer de premiers résultats. \n",
    "\n",
    "Remarque2: pour limiter l'impact du \"bloat\", il vous est recommandé de mettre une taille maximale à l'arbre généré par les opérateurs de mutation et de croisement. Vous pourrez utiliser gp.staticLimit. Sans cela, certaines expériences risquent de prendre un temps et une mémoire considérables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse 1.1 : \n",
    "\n",
    "**Pour la stratégie élitiste**: cette stratégie trouve la forme de la fonction f1(x,y)=x*y+cos(x) 2 fois au total sur 10 essais et la fonction f2(x,y,z)=x²+y²+z² 1 fois.Cette stratégie a erreur moyenne faible (en dessous de 0.1 la plupart du temps pour la fonction 1; pour la fonction 2, l'erreur est souvent au même niveau que NSGA-2 voire en dessous mais il arrive aussi que l'erreur soit plus mauvaise >1  ).Pour les fonctions 1 et 2, la taille moyenne des arbres est d'environ 10 dans quasiment tous les cas pour la fonction 1 et souvent un peu moins pour la fonction 2.\n",
    "\n",
    "\n",
    "**Pour la stratégie double tournoi**: pour la fonction f1 et f2, la stratégie ne trouve pas la fonction. De plus, l'erreur moyenne est plus élevée avec cette méthode que les autres (entre 0.1 et 1 la plupart du temps pour f1 et entre 1 et 3 pour la fonction f2).Cette méthode renvoie les arbres qui sont en moyenne les plus petits (quasiment toujours à 6 ou moins pour la fonction 1 et systématiquement 3 pour la fonction 2).\n",
    "\n",
    "**Pour la stratégie NSGA-2**: pour la fonction 1, la stratégie trouve 2 fois la fonction et l'une des deux fois, 2 arbres sont générés inversant x et y dans la multiplication.L'erreur moyenne est ici inférieure à 0.1 dans tous les cas(voire encore plus faible dans certains cas). NSGA-2 produit les arbres les plus grands en moyenne (10 ou plus voire beaucoup plus ).\n",
    "Pour la fonction 2, la stratégie ne trouve jamais la bonne fonction mais l'erreur moyenne est toujours en dessous de 1.NSGA-2 produit des arbres de taille similaire à la stratégie élitiste mais il arrive parfois d'avoir des arbres beaucoup plus grands.\n",
    "\n",
    "De manière générale, la stratégie double tournoi renvoient les arbres les plus petits mais l'erreur moyenne est aussi la moins bonne des trois. La stratégie élitiste donne de moins bons résultats en matière d'erreur moyenne mais les arbres produits semblent en moyenne moins grands que pour NSGA-2. Cette dernière semble donner les meilleurs résultats pour l'erreur moyenne mais aussi les arbres les plus grands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de Résultat pour élitiste :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/elitist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de résultat pour double tournoi :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/double-tournois.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de résultat pour NSGA-2 :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/nsga2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2-** Ajoutez du bruit à vos fonctions et observez le résultat obtenu (mettez des valeurs qui sont faibles devant les données, par exemple 0.0001)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse 1.2 :\n",
    "\n",
    "**Pour la stratégie élitiste :** avec la fonction 1 la méthode trouve 2 fois la bonne fonction. En dehors des 2 fois où la fonction est trouvée, l'erreur moyenne est entre 0.1 et un peu plus de 1. La taille des arbres trouvés ici est quasiment toujours en moyenne de 6 mais peu des fois aller au-delà de 30.\n",
    "Avec la fonction f2, on ne trouve jamais la bonne fonction mais l'erreur moyenne est environ en dessous de 1 presque tout le temps (ou légèrement au-dessus).Cette méthode trouve le plus souvent des arbres de taille aux alentours de 10 mais peut aussi trouver des arbres de taille bien supérieure (40 ou 80 par exemple).\n",
    "\n",
    "**Pour la stratégie double tournoi :** avec la fonction 1 la méthode trouve 1 fois la bonne fonction.  Mise à pars la fois où la fonction a été trouvée, l'erreur moyenne se situe autour de 0.7. La taille des arbres trouvés est toujours inférieure ou égale à 6. Dans le cas où la fonction est trouvée, c'est 6 sinon c'est autour de 3 ou 4 en moyenne.\n",
    "Avec la fonction f2, on ne trouve jamais la bonne fonction, l'erreur moyenne est ici toujours autour de 2. Cette méthode trouve toujours des arbres de taille 3 environ.\n",
    "\n",
    "**Pour la stratégie NSGA-2 :** avec la fonction 1 cette méthode ne trouve jamais la fonction. Dans ce cas l'erreur moyenne est toujours en dessous de 1 et quasiment toujours en dessous de 0.5. La taille des arbres est plutôt variable mais on peut voir qu'ils sont généralement soit environ de taille 10-11, soit de taille autour de 5.\n",
    "Avec la fonction f2, on ne trouve jamais la bonne fonction mais la plupart du temps l'erreur moyenne est significativement en dessous de 1 (sauf une fois où elle était à 2).La plupart des arbres trouvés par cette méthode sont de taille proche de 10 mais certains sont beaucoup plus grands( plus de 100).\n",
    "\n",
    "On peut donc voir que dans tous les cas la méthode double tournois donne les pires résultats en matière d'erreur mais les meilleurs pour ce qui est de la taille et dans le cas de la première fonction, cette méthode trouve plus souvent la solution que NSGA-2 mais moins que la méthode élitiste. La méthode élitiste tend à trouver plus souvent la solution pour certaines fonctions mais l'erreur moyenne est meilleure du coté de NSGA-2 et ce de façon plus courante. Pour ce qui est de la taille des arbres, la méthode élitiste semble très légèrement meilleure pour produire de plus petits arbres plus souvent que NSGA-2.\n",
    "\n",
    "On remarque aussi que pour toutes les méthodes les résultats sont moins bon que lorsqu'il n'y a pas de bruit dans les données. Toutes les méthodes semblent affectées de façon similaire mais les méthodes les plus précises au départ (NSGA-2 et élitiste) paraissent plus touchées que double tournoi. \n",
    "\n",
    "De manière générale on peut conclure que pour trouver le plus souvent un résultat le plus proche possible de la fonction initiale, NSGA-2 semble être la meilleure méthode, cependant si l'objectif est de se rapprocher de la fonction avec le plus petit arbre possible c'est le double tournois qui donne les meilleurs résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de résultat d'élitiste :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/elitist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de résultat de double tournoi :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/dt+noise.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de résultat pour NSGA-2 :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/nsga2+noise.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3- (option) ** Utilisez le code d'apprentissage du pendule vue lors de la séance précédente pour générer des données et essayez d'apprendre un modèle du pendule (un arbre par dimension de l'espace d'état)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pour aller plus loin (non demandé pour le TME)** pour apprendre des modèles en écartant les solutions triviales et en gérant mieux les constantes, vous pouvez regarder ce qui a été fait notamment dans les articles suivants:\n",
    "* Schmidt, M., & Lipson, H. (2009). Distilling free-form natural laws from experimental data. science, 324(5923), 81-85.\n",
    "* Derner, E., Kubalík, J., Ancona, N., & Babuška, R. (2019). Symbolic Regression for Constructing Analytic Models in Reinforcement Learning. arXiv preprint arXiv:1903.11483."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fitness & Nouveauté\n",
    "\n",
    "L'environnement `FastsimSimpleNavigation-v0` de gym_fastsim permet de lancer des expériences de navigation avec un robot à roues naviguant dans un labyrinthe. Vous allez dans cette partie reproduire les expériences de Lehman et Stanley sur la recherche de nouveauté. Vous allez faire différentes variantes de cette expérience, certaines étant en mono- d'autres étant en multi-objectif. Pour simplifier, dans tous les cas, vous utiliserez NSGA-2, qui est équivalent à une stratégie élitiste en mono-objectif.\n",
    "\n",
    "Pour utiliser l'environnement `FastsimSimpleNavigation-v0`, un script d'installation (linux) vous est fourni: `install-dependencies.sh`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2.1-**  Lancer une première expérience dans laquelle le robot doit atteindre la sortie du labyrinthe. Vous pourrez essayer avec la reward de l'expérience, qui est une reward binaire (sortie atteinte ou non) et avec une fitness plus continue dans laquelle la récompense est la distance à la sortie (à minimiser donc). Pour observer le comportement de la recherche effectuée, vous pourrez écrire la position du robot à la fin de l'évaluation et ensuite tracer ces positions avec les fonctions fournies dans `maze_plot.py` (vous pouvez aussi tracer les trajectoires, mais comme il y a 2000 positions par évaluation, dans ce cas, vous pourrez n'écrire qu'une position sur 100, par exemple).\n",
    "\n",
    "Quelles parties de l'espace ont été explorées dans les deux cas ? Est-ce que la sortie est atteinte (vous vous limiterez à 200 générations) ? Si oui, au bout de combien de générations ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse 2.1 :\n",
    "\n",
    "* **Résumer :** Dans les deux cas avec une méthode uniquement FIT, notre algorithme semble, converger vers un minimum local, et n'arrive pas à atteindre la sortie (environ position x=100 et y=50), et cela semble logique, car notre fonction cherche à chaque itération à trouver la meilleure fit possible et la part \"d'exploration\" n'est pas suffisante. Sur l'animation, on peut voir que l'algorithme arrive à trouver des solutions avec peu de variantes (jusqu'à la gen0019), pour trouver une meilleure solution, mais n'arrive pas à sortir du \"cul-de-sac\", le graphe des best fit et fit de chaque itération, nous montre que l'algorithme cherche à chaque itération une meilleur fit ce qui montre de la forte convergence et du fait d'être bloqué dans des minimums locaux. Le graphe bd, nous explique aussi le fait qu'une fois l'algorithme trouve un bon fit sur une trajectoire, l'algorithme à très peu de variante et les zones avec beaucoup de points correspond a nos dernières trajectoires dans l'animation, et l'algorithme semble avoir continué à chercher dans ce \"cul-de-sac\", mais n'a pas réussi a trouvé mieux de l'itération 107 à 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'animation suivante, représente l'évolution des trajectoires à chaque nouvelle de l'**algorithme FIT**, l'axe des x et y représente les coordonnées.\n",
    "\n",
    "\n",
    "(si vous n'arrivez pas à voir le gif ci-dessous, toutes les images/logs sont dans le fichier \"Donnée_des_tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SegmentLocal](Donnée_des_tests/FIT.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titre** : l'évolution du best fit et de la génération courante trouver (axe y) trouver au cours des 200 itérations (axe x), de l'**algorithme FIT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/FIT.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titre** : Point d'arriver de chaque itération"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/plot-FIT/bd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2-** Lancer la même expérience, mais avec un critère de nouveauté. Vous pourrez pour cela partir du code fourni pour le calcul de nouveauté (`novelty_search.py`) et le compléter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse 2.2 : \n",
    "\n",
    "* **Résumer :** Ici, par rapport à la méthode FIT, la part \"d'exploration\" semble trop importante, l'algorithme à beaucoup de mal à converger vers un meilleur fit, et ainsi trouvé la sortie, ce qui montre les faibles solutions trouvé au bout de 200 itérations, ici juste 2 meilleurs fit trouver (à la génération 23 et 52), et le graphe de l'évolution du best fit avec le fit de chaque itération montre que l'algorithme ne converge pas du tout et trouve des best fit par hasard. Le graphe bd, nous montre que l'algorithme n'a pas cherché à essayer de se rapprocher de la sortie, mais s'est éparpiller dans tous les sens, ce qui montre de la non-convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'animation suivante, représente l'évolution des trajectoires à chaque nouvelle de l'**algorithme NS**, l'axe des x et y représente les coordonnées.\n",
    "\n",
    "(si vous n'arrivez pas à voir le gif ci-dessous, toutes les images/logs sont dans le fichier \"Donnée_des_tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SegmentLocal](Donnée_des_tests/NS.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titre** : L'évolution du best fit et de la génération courante trouver (axe y) trouver au cours des 200 itérations (axe x), de l'**algorithme NS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/NS.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titre** : Point d'arriver de chaque itération"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/plot-NS/bd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3-** Utiliser en même temps la fitness et le critère de nouveauté avec NSGA-2. Mesurez le temps moyen pour atteindre la sortie. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réponse 2.3 : \n",
    "\n",
    "* **Résumer :** En combinant les deux méthodes précédent **FIT+NS**, où FIT corrige la forte tendance de partir dans tous les sens, et NS qui corrige la forte convergence qui a tendance à aller dans des minimums locaux. On peut voir ici, en plus du fait que l'algorithme a réussi à trouver la sortie, il l'a trouvé assez rapidement, en moyenne au bout d'une vingtaine-trentaine d'itérations (l'algorithme continue à s'améliorer un peu par la suite de quelques dixièmes d'unité après la virgule, comme on peut voir sur le graphe de l'évolution des fits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'animation suivante, représente l'évolution des trajectoires à chaque nouvelle de l'**algorithme FIT+NS**, l'axe des x et y représente les coordonnées.\n",
    "\n",
    "(si vous n'arrivez pas à voir le gif ci-dessous, toutes les images/logs sont dans le fichier \"Donnée_des_tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SegmentLocal](Donnée_des_tests/FIT+NS.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titre** : L'évolution du best fit et de la génération courante trouver (axe y) trouver au cours des 200 itérations (axe x), de l'**algorithme FIT+NS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/FIT+NS.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titre** : Point d'arriver de chaque itération"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Donnée_des_tests/plot-NS+FIT/bd.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
